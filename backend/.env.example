# Backend Environment Variables
# Copy this file to .env and adjust as needed

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Matching Configuration
SIMILARITY_THRESHOLD=85.0

# ============================================================
# Embedding Configuration
# ============================================================

# OpenAI API Key (required for 'openai-small' or 'openai-large' modes)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Default embedding mode: 'openai-small', 'openai-large', 'local', or 'disabled'
# - openai-small: Balanced quality/cost (recommended, ~85% accuracy, $0.02/1M tokens)
# - openai-large: Best quality (~90% accuracy, $0.13/1M tokens)
# - local: Privacy mode, runs locally (~75% accuracy, no cost, uses ~150MB RAM)
# - disabled: No embeddings, fuzzy matching only (~61% accuracy)
DEFAULT_EMBEDDING_MODE=openai-small

# Local embedding model (used in 'local' mode)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding dimensions (lower = faster, higher = more accurate)
# OpenAI default is 1536, we use 512 for speed
EMBEDDING_DIMENSIONS=512

# Similarity score weights (must sum to ~1.0)
# Controls how much each component contributes to final similarity score
WRATIO_WEIGHT=0.40          # Fuzzy string matching (handles typos)
TOKEN_SET_WEIGHT=0.15       # Token overlap (reduced from 0.40 to fix shared-word problem)
EMBEDDING_WEIGHT=0.45       # Semantic similarity (NEW - understands context)

# GMM Adaptive Threshold Configuration
USE_ADAPTIVE_THRESHOLD=False
GMM_MIN_SAMPLES=50
GMM_MAX_PAIRS=50000
GMM_FALLBACK_T_HIGH=92.0
GMM_FALLBACK_T_LOW=80.0

# ============================================================
# Stratified Sampling Configuration
# ============================================================

# Blocking Configuration
# Min block size: Blocks smaller than this are treated as singletons (no pairs)
BLOCKING_MIN_BLOCK_SIZE=2

# Max pairs per block: Cap comparisons per block to prevent giant blocks from dominating
BLOCKING_MAX_BLOCK_PAIRS=5000

# Sampling Budget Split: Within-Block vs Cross-Block
# Within-block: Sample from names in same block (potentially similar)
# Cross-block: Sample from names in different blocks (rare matches)
SAMPLING_WITHIN_BLOCK_PCT=0.95
SAMPLING_CROSS_BLOCK_PCT=0.05

# Within-Block Allocation: Proportional vs Floor
# Proportional: Larger blocks get more samples (80%)
# Floor: Even distribution ensures small blocks get represented (20%)
SAMPLING_PROPORTIONAL_PCT=0.80
SAMPLING_FLOOR_PCT=0.20

# Reproducibility: Fixed RNG seed for deterministic sampling
# Change this value to get different (but still reproducible) samples
SAMPLING_RNG_SEED=42

# ============================================================
# LLM Borderline Assessment Configuration (Optional)
# ============================================================

# Enable LLM assessment for borderline pairs in HAC mode
# WARNING: This will significantly increase processing time (30-60s for 500 names)
# and API costs (~$2.50 per 500 names). Recommended only when accuracy is critical.
LLM_BORDERLINE_ENABLED=False

# OpenAI model for assessment (default: gpt-4o-mini)
# Options:
#   - gpt-4o-mini: Balanced cost/quality ($0.15 per 1M input tokens, $0.60 per 1M output)
#                  Recommended for most use cases (~$0.0002 per assessment)
#   - gpt-4o: Higher quality ($2.50 per 1M input tokens, $10.00 per 1M output)
#             Use when maximum accuracy required (~$0.003 per assessment)
LLM_BORDERLINE_MODEL=gpt-4o-mini

# Borderline distance range (distance = 1 - similarity/100)
# Default: 0.27-0.57 (similarity 43-73%, straddles HAC threshold of 58%)
# This range captures ambiguous cases where LLM can add value
LLM_BORDERLINE_DISTANCE_LOW=0.27
LLM_BORDERLINE_DISTANCE_HIGH=0.57

# Batch size for parallel API calls (higher = faster but more memory)
# Recommended: 10-20 for balanced performance
LLM_BORDERLINE_BATCH_SIZE=10

# Adjustment strength: How much LLM affects similarity scores (0.0-1.0)
# Lower = conservative (LLM gently nudges scores)
# Higher = aggressive (LLM has more influence)
# Recommended: 0.15 (15% max adjustment)
LLM_BORDERLINE_ADJUSTMENT_STRENGTH=0.15

# ============================================================
# ANTI-HALLUCINATION GUARDRAILS (CRITICAL)
# ============================================================

# Minimum confidence threshold (0.0-1.0)
# LLM decisions with confidence below this are converted to "unknown"
# Higher = stricter (more "unknown" responses, safer)
# Lower = more permissive (fewer "unknown", higher risk)
# Recommended: 0.60 (60% confidence minimum)
LLM_MIN_CONFIDENCE=0.60

# Allow "unknown" responses (STRONGLY RECOMMENDED: True)
# When True: LLM can respond "unknown" if uncertain (prevents hallucination)
# When False: LLM forced to choose "same" or "different" (NOT RECOMMENDED - increases guessing)
# NEVER set to False unless you understand the hallucination risks
LLM_ALLOW_UNKNOWN=True

# Logging
LOG_LEVEL=INFO
